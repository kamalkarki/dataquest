{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot = 278\n",
      " ----- Computation time = 1.2421049999997713ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "for i in range(len(x1)):\n",
    "    dot+= x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 15)\n",
      "outer = [[81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [63. 14. 14. 63.  0. 63. 14. 35.  0.  0. 63. 14. 35.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      " ----- Computation time = 1.456078999999999ms\n"
     ]
    }
   ],
   "source": [
    "### CLASSIC OUTER PRODUCT IMPLEMENTATION ###\n",
    "import numpy as np\n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1),len(x2))) # we create a len(x1)*len(x2) matrix with only zeros\n",
    "print(outer.shape)\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i]*x2[j]\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0925802  0.94898562 0.73188394 0.97628241 0.89513664 0.44469965\n",
      "  0.12437397 0.82804115 0.30195501 0.54852228 0.88567133 0.35129791\n",
      "  0.89841808 0.57484798 0.09024831]\n",
      " [0.68752481 0.33031666 0.89032618 0.3757547  0.57944677 0.33582477\n",
      "  0.23697542 0.85730859 0.63108608 0.27387488 0.93303861 0.2584311\n",
      "  0.13049627 0.72771807 0.40765242]\n",
      " [0.77884018 0.67061739 0.83040704 0.61408577 0.28631846 0.87241749\n",
      "  0.73041814 0.92553989 0.92923642 0.12901747 0.64540649 0.0952851\n",
      "  0.95264094 0.96580448 0.84880755]]\n",
      "(3, 15)\n",
      "gdot = [23.29110837 24.40232907 33.02427799]\n",
      " ----- Computation time = 0.2593590000001811ms\n"
     ]
    }
   ],
   "source": [
    "### CLASSIC GENERAL DOT PRODUCT IMPLEMENTATION ###\n",
    "W = np.random.rand(3,len(x1)) # Random 3*len(x1) numpy array\n",
    "print(W)\n",
    "print(W.shape)\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j]*x1[j]\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(gdot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4, 4, 3)\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(10*4*4*3).reshape(10, 4, 4, 3)\n",
    "print(a.shape)\n",
    "print(a[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4, 4, 3)\n",
      "(10, 4, 4, 3)\n",
      "(10, 4, 12)\n",
      "(10, 48)\n",
      "(48, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# to keep the example easy to view, we use 10 examples of pictures.  Each picture is of size 4x4 pixels, and each pixel contains 3 (r,g,b) values\n",
    "# we first fill an array with sequential 480 entries (10*4*4*3) and then reshape it into an 10x4x4x3 array\n",
    "a=np.arange(10*4*4*3).reshape(10, 4, 4, 3)\n",
    "print(a.shape)\n",
    "#print(a)\n",
    "\n",
    "# we can reshape arrays using .reshape method\n",
    "# array axis are numbered from 0 and accessed through .shape method\n",
    "# if a specific axis is specified to .reshape, that axis is preserved and the rest of the axis' are reshaped/flattened\n",
    "# a -1 argument tells numpy to figure out the dimensions of reshaped axis \n",
    "\n",
    "# flatten the innermost axis (the r,g,b values), which are already flat, so this operation does nothing\n",
    "aflat=a.reshape(a.shape[0],a.shape[1],a.shape[2],-1)\n",
    "print(aflat.shape)\n",
    "#print(aflat)\n",
    "\n",
    "# flatten the innermost two axis (r,g,b values in each pixel row). 4x3 gets flattened to 12 color values\n",
    "aflat=a.reshape(a.shape[0],a.shape[1],-1)\n",
    "print(aflat.shape)\n",
    "#print(aflat)\n",
    "\n",
    "# flatten the innermost three axis (r,g,b values in each pixel row, reading left to right and top to bottom). 4x4x3 gets flattened to 48 values.  this operation flattens each individual image\n",
    "aflat=a.reshape(a.shape[0],-1)\n",
    "print(aflat.shape)\n",
    "#print(aflat)\n",
    "\n",
    "# at this point, the rows have 'examples' (the training or test cases) and columns have the 'features' (the color values).  to get the features in rows and examples in columns, we transpose the matrix using the .T method\n",
    "aflatt=aflat.T\n",
    "print(aflatt.shape)\n",
    "#print(aflatt)\n",
    "\n",
    "# fun exercise\n",
    "# to create random pixel noise to test your trained network, try the following\n",
    "# x_test=np.random.randint(255,size=(64*64*3,209))\n",
    "# print(x_test.shape)\n",
    "# print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "(12288, 10)\n",
      "12288\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(10*64*64*3).reshape(10, 64, 64, 3)\n",
    "print(a.shape)\n",
    "\n",
    "b= a.reshape(a.shape[0],-1).T\n",
    "print(b.shape)\n",
    "print (b.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "(12288, 1)\n"
     ]
    }
   ],
   "source": [
    "#for the derivate \n",
    "A = np.arange(1,11).reshape(10,1)\n",
    "print(A.shape)\n",
    "\n",
    "# now with out dot product --- A * b should be as b shape due to broadcasting nope not happening\n",
    "#print( (b * A).shape)\n",
    "# but dot procut make it 12288 * 1 vector\n",
    "\n",
    "print( np.dot(b,A).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "(12288, 10)\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(1,11).reshape(10,1)\n",
    "print(A.shape)\n",
    "\n",
    "#now big part\n",
    "\n",
    "diff = b * A.T\n",
    "print(diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]]\n",
      "(2, 2)\n",
      "[[4 5]\n",
      " [6 7]]\n",
      "(2, 2)\n",
      "[[ 0  5]\n",
      " [12 21]]\n",
      "[[ 6  7]\n",
      " [26 31]]\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(1)\n",
    "a = np.arange(4).reshape(2,2)\n",
    "#print(type(a) )\n",
    "print(a)\n",
    "print(a.shape)\n",
    "b= np.arange(4,8).reshape(2,2)\n",
    "#print(type(b))\n",
    "print(b)\n",
    "print(b.shape)\n",
    "c = a * b\n",
    "d = np.dot(a,b)\n",
    "print(c)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4).reshape(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(1,210).reshape(1,209)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 209)\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "   19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "   37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "   55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "   73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "   91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      "  109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      "  127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      "  145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      "  163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
      "  181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
      "  199 200 201 202 203 204 205 206 207 208 209]]\n"
     ]
    }
   ],
   "source": [
    "B = np.arange(1,210).reshape(1,209)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(A -B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    #print(m)\n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    \n",
    "    #A = sigmoid(np.transpose(w).dot(X) + b )                                     # compute activation\n",
    "    A = sigmoid( np.dot(w.T,X) + b )\n",
    "    # 1 * 209 a  row vector will be returned to A\n",
    "    \n",
    "    cost = (-1/m)* np.sum(  Y * np.log(A) + ( (1 - Y ) * np.log( 1 - A ) ) )      # compute cost\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    # A- Y is 1 * 209 vector\n",
    "    dw = (1/m )* np.dot(X,(A-Y).T)\n",
    "    # (12288, 1) above line is a column vector for all the \n",
    "    db = (1/m) * np.sum( A - Y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
