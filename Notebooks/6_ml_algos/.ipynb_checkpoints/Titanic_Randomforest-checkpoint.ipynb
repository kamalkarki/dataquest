{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # petal length and width\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamlesh/anaconda3/envs/Py35/lib/python3.5/site-packages/sklearn/tree/export.py:399: DeprecationWarning: out_file can be set to None starting from 0.18. This will be the default in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        feature_names=iris.feature_names[2:],\n",
    "        class_names=iris.target_names,\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('/home/kamlesh/AnacondaProjects/DeepLearning/Projects/kaggle/titanic/train_modified.csv')\n",
    "holdout = pd.read_csv('/home/kamlesh/AnacondaProjects/DeepLearning/Projects/kaggle/titanic/holdout_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'PassengerId', 'Age_categories_Missing',\n",
       "       'Age_categories_Infant', 'Age_categories_Child',\n",
       "       'Age_categories_Teenager', 'Age_categories_Young Adult',\n",
       "       'Age_categories_Adult', 'Age_categories_Senior', 'Pclass_1', 'Pclass_2',\n",
       "       'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n",
       "       'Embarked_S', 'SibSp_scaled', 'Parch_scaled', 'Fare_scaled',\n",
       "       'Fare_categories_0-12', 'Fare_categories_12-50',\n",
       "       'Fare_categories_50-100', 'Fare_categories_100+', 'Title_Master',\n",
       "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer', 'Title_Royalty',\n",
       "       'Cabin_type_A', 'Cabin_type_B', 'Cabin_type_C', 'Cabin_type_D',\n",
       "       'Cabin_type_E', 'Cabin_type_F', 'Cabin_type_G', 'Cabin_type_T',\n",
       "       'Cabin_type_Unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data set\n",
    "\n",
    "all_x = train.drop(['Survived','PassengerId'],axis = 1)\n",
    "all_y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "scores = cross_val_score(clf, all_x, all_y, cv=10)\n",
    "accuracy_rf = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"criterion\": [\"entropy\", \"gini\"],\n",
    "                   \"max_depth\": [5, 10],\n",
    "                   \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": [1, 5],\n",
    "                   \"min_samples_split\": [3, 5],\n",
    "                   \"n_estimators\": [6, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [6, 9], 'criterion': ['entropy', 'gini'], 'max_depth': [5, 10], 'min_samples_leaf': [1, 5], 'min_samples_split': [3, 5], 'max_features': ['log2', 'sqrt']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = GridSearchCV(clf,param_grid=hyperparameters,cv=10)\n",
    "g.fit(all_x,all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=9, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 9}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84287317620650959"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now on the basis of the returned parameters lets train a random forest\n",
    "rf = RandomForestClassifier(n_estimators=9,criterion='entropy',max_depth=10,max_features='log2',min_samples_leaf=1\n",
    "                           ,min_samples_split = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=9, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(all_x,all_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Making an ensemble for titanic with out feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "# svc\n",
    "# random forest\n",
    "# logistic regression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "lr = LogisticRegression(random_state = 1)\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "rnd_clf = RandomForestClassifier(random_state=1)\n",
    "svm_clf = SVC(random_state=1,probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', lr), ('rf', rnd_clf), ('svc', svm_clf),('knn',knn)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFore...owski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform'))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(all_x, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "holdout_no_id = holdout.drop(['PassengerId'],axis=1)\n",
    "holdout_predictions = voting_clf.predict(holdout_no_id)\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"submission_3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.833894500561\n",
      "RandomForestClassifier 0.945005611672\n",
      "SVC 0.800224466891\n",
      "KNeighborsClassifier 0.945005611672\n",
      "VotingClassifier 0.897867564534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (lr, rnd_clf, svm_clf,knn, voting_clf):\n",
    "    clf.fit(all_x, all_y)\n",
    "    y_pred = clf.predict(all_x)\n",
    "    print(clf.__class__.__name__, accuracy_score(train['Survived'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only 2 ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "rnd_clf = RandomForestClassifier(random_state=1)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', lr), ('rf', rnd_clf), ('svc', svm_clf),('knn',knn)],\n",
    "    voting='soft')\n",
    "\n",
    "\n",
    "voting_clf.fit(all_x, all_y)\n",
    "holdout_no_id = holdout.drop(['PassengerId'],axis=1)\n",
    "holdout_predictions = voting_clf.predict(holdout_no_id)\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"eneemble4.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42,oob_score=True)\n",
    "bag_clf.fit(all_x, all_y)\n",
    "y_pred = bag_clf.predict(all_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86531986532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(all_y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_predictions = bag_clf.predict(holdout_no_id)\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"eneemble4.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95847362514\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(all_x, all_y)\n",
    "y_pred_tree = tree_clf.predict(all_x)\n",
    "print(accuracy_score(all_y, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_predictions = tree_clf.predict(holdout_no_id)\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"eneemble5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "ada_clf.fit(all_x, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_predictions = ada_clf.predict(holdout_no_id)\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"eneemble4.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import xgboost\n",
    "except ImportError as ex:\n",
    "    print(\"Error: the xgboost library is not installed.\")\n",
    "    xgboost = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/15/606f81a2b8a8e82eaa10683cb3f3074905ec65d3bcef949e3f0909f165a5/xgboost-0.80-py2.py3-none-manylinux1_x86_64.whl (15.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 15.8MB 86kB/s eta 0:00:01  6% |██                              | 962kB 1.3MB/s eta 0:00:12    8% |██▋                             | 1.3MB 1.0MB/s eta 0:00:14    12% |████                            | 2.0MB 420kB/s eta 0:00:33    20% |██████▋                         | 3.3MB 1.3MB/s eta 0:00:11    22% |███████▎                        | 3.6MB 779kB/s eta 0:00:16    61% |███████████████████▉            | 9.8MB 997kB/s eta 0:00:07\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/kamlesh/anaconda3/envs/Py35/lib/python3.5/site-packages (from xgboost) (1.15.1)\n",
      "Requirement already satisfied: scipy in /home/kamlesh/anaconda3/envs/Py35/lib/python3.5/site-packages (from xgboost) (1.1.0)\n",
      "\u001b[31mmkl-fft 1.0.4 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mtoree 0.1.0 has requirement jupyter-client<5.0,>=4.0, but you'll have jupyter-client 5.2.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow-tensorboard 0.4.0rc3 has requirement bleach==1.5.0, but you'll have bleach 2.1.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow-tensorboard 0.4.0rc3 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.15.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 1.10.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.80\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xgboost.sklearn.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.fit(all_x,all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_predictions = x.predict(holdout_no_id)\n",
    "\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"eneemble4.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
